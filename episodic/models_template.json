{
  "_comment": "Model configuration for Episodic. This file defines available models, their types, and parameters.",
  "_version": "1.0",
  "_pricing_note": "Optional pricing can be added to any model. Format: {\"input\": 0.003, \"output\": 0.015, \"unit\": \"per_1k_tokens\", \"last_updated\": \"YYYY-MM-DD\"}",
  
  "providers": {
    "openai": {
      "display_name": "OpenAI",
      "models": [
        {
          "name": "gpt-4o-mini",
          "display_name": "GPT-4o Mini",
          "type": "chat",
          "parameters": "8B",
          "context_window": 128000
        },
        {
          "name": "gpt-4o",
          "display_name": "GPT-4o",
          "type": "chat",
          "parameters": "200B+",
          "context_window": 128000
        },
        {
          "name": "o3",
          "display_name": "o3 (Reasoning)",
          "type": "chat",
          "parameters": null,
          "context_window": 128000
        },
        {
          "name": "o4-mini", 
          "display_name": "o4-mini (Reasoning)",
          "type": "chat",
          "parameters": null,
          "context_window": 128000
        },
        {
          "name": "gpt-3.5-turbo",
          "display_name": "GPT-3.5 Turbo",
          "type": "chat",
          "parameters": "175B",
          "context_window": 16385
        },
        {
          "name": "gpt-3.5-turbo-instruct",
          "display_name": "GPT-3.5 Turbo Instruct",
          "type": "instruct",
          "parameters": "175B",
          "context_window": 4096
        },
        {
          "name": "gpt-4",
          "display_name": "GPT-4",
          "type": "chat",
          "parameters": "175B+",
          "context_window": 8192
        },
        {
          "name": "gpt-4.5",
          "display_name": "GPT-4.5",
          "type": "chat",
          "parameters": null,
          "context_window": 128000
        }
      ]
    },
    
    "anthropic": {
      "display_name": "Anthropic",
      "models": [
        {
          "name": "claude-opus-4-20250514",
          "display_name": "Claude 4 Opus",
          "type": "both",
          "parameters": "~1T",
          "context_window": 200000
        },
        {
          "name": "claude-sonnet-4-20250522",
          "display_name": "Claude 4 Sonnet",
          "type": "both",
          "parameters": "~300B",
          "context_window": 200000
        },
        {
          "name": "claude-3-opus-20240229",
          "display_name": "Claude 3 Opus",
          "type": "both",
          "parameters": "~1T",
          "context_window": 200000
        },
        {
          "name": "claude-3.7-sonnet-20250219",
          "display_name": "Claude 3.7 Sonnet",
          "type": "both",
          "parameters": "~300B",
          "context_window": 200000
        },
        {
          "name": "claude-3.5-sonnet-20241022",
          "display_name": "Claude 3.5 Sonnet",
          "type": "both",
          "parameters": "~300B",
          "context_window": 200000
        },
        {
          "name": "claude-3.5-haiku-20241022",
          "display_name": "Claude 3.5 Haiku",
          "type": "both",
          "parameters": "~70B",
          "context_window": 200000
        }
      ]
    },
    
    "google": {
      "display_name": "Google",
      "models": [
        {
          "name": "gemini-2.5-pro",
          "display_name": "Gemini 2.5 Pro",
          "type": "both",
          "parameters": null,
          "context_window": 2097152
        },
        {
          "name": "gemini-2.5-flash",
          "display_name": "Gemini 2.5 Flash",
          "type": "both",
          "parameters": null,
          "context_window": 1048576
        },
        {
          "name": "gemini-ultra",
          "display_name": "Gemini Ultra",
          "type": "both",
          "parameters": null,
          "context_window": 32768
        },
        {
          "name": "gemini-1.5-pro",
          "display_name": "Gemini 1.5 Pro",
          "type": "both",
          "parameters": null,
          "context_window": 2097152
        }
      ]
    },
    
    "ollama": {
      "display_name": "Ollama (Local)",
      "api_base": "http://localhost:11434",
      "models": [
        {
          "name": "llama3",
          "display_name": "Llama 3",
          "type": "chat",
          "detect_params": true
        },
        {
          "name": "llama3:instruct",
          "display_name": "Llama 3 Instruct",
          "type": "instruct",
          "detect_params": true
        },
        {
          "name": "mistral",
          "display_name": "Mistral",
          "type": "chat",
          "detect_params": true
        },
        {
          "name": "mistral:instruct",
          "display_name": "Mistral Instruct",
          "type": "instruct",
          "detect_params": true
        },
        {
          "name": "codellama",
          "display_name": "Code Llama",
          "type": "base",
          "detect_params": true
        },
        {
          "name": "phi3",
          "display_name": "Phi-3",
          "type": "instruct",
          "parameters": "3.8B",
          "detect_params": true
        }
      ]
    },
    
    "lmstudio": {
      "display_name": "LM Studio (Local)",
      "api_base": "http://localhost:1234/v1",
      "models": []
    },
    
    "openrouter": {
      "display_name": "OpenRouter",
      "api_base": "https://openrouter.ai/api/v1",
      "dynamic": true,
      "models": [
        {
          "name": "openrouter/anthropic/claude-opus-4",
          "display_name": "Claude 4 Opus (OR)",
          "type": "both",
          "context_window": 200000
        },
        {
          "name": "openrouter/anthropic/claude-3-sonnet",
          "display_name": "Claude 3 Sonnet (OR)",
          "type": "chat"
        },
        {
          "name": "openrouter/openai/gpt-4",
          "display_name": "GPT-4 (OR)",
          "type": "chat"
        },
        {
          "name": "openrouter/openai/gpt-3.5-turbo",
          "display_name": "GPT-3.5 Turbo (OR)",
          "type": "chat"
        },
        {
          "name": "openrouter/google/gemini-pro",
          "display_name": "Gemini Pro (OR)",
          "type": "chat"
        },
        {
          "name": "openrouter/mistralai/mistral-7b-instruct",
          "display_name": "Mistral 7B Instruct (OR)",
          "type": "instruct",
          "parameters": "7B"
        },
        {
          "name": "openrouter/meta-llama/llama-3.3-70b-instruct",
          "display_name": "Llama 3.3 70B Instruct (OR)",
          "type": "instruct",
          "parameters": "70B"
        },
        {
          "name": "openrouter/qwen/qwen-2-72b-instruct",
          "display_name": "Qwen 2 72B Instruct (OR)",
          "type": "instruct",
          "parameters": "72B"
        },
        {
          "name": "openrouter/moonshotai/kimi-k2",
          "display_name": "Kimi K2 (OR)",
          "type": "chat",
          "parameters": null,
          "context_window": 128000
        },
        {
          "name": "openrouter/databricks/dbrx-instruct",
          "display_name": "DBRX Instruct 132B (OR)",
          "type": "instruct",
          "parameters": "132B"
        },
        {
          "name": "openrouter/nousresearch/hermes-3-405b-instruct",
          "display_name": "Hermes 3 405B Instruct (OR)",
          "type": "instruct",
          "parameters": "405B"
        },
        {
          "name": "openrouter/mistralai/mixtral-8x7b-instruct",
          "display_name": "Mixtral 8x7B Instruct (OR)",
          "type": "instruct",
          "parameters": "8x7B"
        }
      ]
    },
    
    "huggingface": {
      "display_name": "HuggingFace",
      "models": [
        {
          "name": "huggingface/meta-llama/Meta-Llama-3-8B",
          "display_name": "Meta Llama 3 8B",
          "type": "chat",
          "parameters": "8B"
        },
        {
          "name": "huggingface/meta-llama/Meta-Llama-3-70B",
          "display_name": "Meta Llama 3 70B",
          "type": "chat",
          "parameters": "70B"
        },
        {
          "name": "huggingface/meta-llama/Llama-2-7b-chat",
          "display_name": "Meta Llama 2 7B Chat",
          "type": "chat",
          "parameters": "7B"
        },
        {
          "name": "huggingface/Qwen/Qwen-3",
          "display_name": "Alibaba Qwen 3",
          "type": "chat"
        },
        {
          "name": "huggingface/mistralai/Mistral-Small-3.1",
          "display_name": "Mistral Small 3.1",
          "type": "chat",
          "parameters": "7B"
        },
        {
          "name": "huggingface/mistralai/Mixtral-8x7B-Instruct-v0.1",
          "display_name": "Mixtral 8x7B Instruct",
          "type": "instruct",
          "parameters": "8x7B"
        },
        {
          "name": "huggingface/deepseek-ai/DeepSeek-R1-0528",
          "display_name": "DeepSeek R1-0528",
          "type": "chat"
        },
        {
          "name": "huggingface/google/gemma-7b",
          "display_name": "Google Gemma 7B",
          "type": "chat",
          "parameters": "7B"
        },
        {
          "name": "huggingface/tiiuae/falcon-40b-instruct",
          "display_name": "Falcon 40B Instruct",
          "type": "instruct",
          "parameters": "40B"
        },
        {
          "name": "huggingface/01-ai/Yi-1.5-34B-Chat",
          "display_name": "Yi 1.5 34B Chat",
          "type": "chat",
          "parameters": "34B"
        },
        {
          "name": "huggingface/bigscience/bloom",
          "display_name": "BLOOM 176B",
          "type": "base",
          "parameters": "176B"
        },
        {
          "name": "huggingface/EleutherAI/gpt-neox-20b",
          "display_name": "GPT-NeoX 20B",
          "type": "base",
          "parameters": "20B"
        }
      ]
    }
  },
  
  "type_patterns": {
    "instruct": [
      "instruct", "instruction", "-inst", 
      "alpaca", "vicuna", "wizardlm", "wizard",
      "phi3", "phi-3", "phi2", "phi-2",
      "zephyr", "openhermes", "hermes",
      "solar", "starling", "openchat",
      "yi-", "qwen", "deepseek",
      "gemma:2b-instruct", "gemma:instruct",
      "minichat", "dolly", "stablelm"
    ],
    
    "chat": [
      "chat", "conversation", "dialogue",
      "assistant", "turbo", "claude",
      "gpt-4", "gpt-3.5", "gpt4", "gpt3",
      "llama-2-.*-chat", "llama-3-.*-chat",
      "llama2:.*chat", "llama3:.*chat",
      "mixtral", "command", "coral",
      "bard", "gemini", "palm"
    ],
    
    "base": [
      ":base", "-base", "base-",
      "completion", "davinci", "curie", "babbage", "ada",
      "bloom", "gpt-neox", "opt-",
      "pythia", "galactica", "flan-ul2"
    ]
  },
  
  "type_indicators": {
    "instruct": "[I]",
    "chat": "[C]",
    "base": "[B]",
    "both": "[CI]",
    "unknown": "[?]"
  }
}